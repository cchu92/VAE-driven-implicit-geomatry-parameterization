\doxysection{main\+\_\+train\+\_\+on\+\_\+\+GPU.\+py}
\hypertarget{main__train__on___g_p_u_8py_source}{}\label{main__train__on___g_p_u_8py_source}\index{D:/Dropbox/Dropbox/Fraunhofer\_Cluster/code\_for\_ITWM/VAE\_unit\_cell\_data/src/main\_train\_on\_GPU.py@{D:/Dropbox/Dropbox/Fraunhofer\_Cluster/code\_for\_ITWM/VAE\_unit\_cell\_data/src/main\_train\_on\_GPU.py}}
\mbox{\hyperlink{main__train__on___g_p_u_8py}{Go to the documentation of this file.}}
\begin{DoxyCode}{0}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00001}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u}{00001}}\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00002}00002\ \textcolor{keyword}{import}\ torch}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00003}00003\ \textcolor{keyword}{import}\ torchvision}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00004}00004\ \textcolor{keyword}{from}\ torch\ \textcolor{keyword}{import}\ nn}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00005}00005\ \textcolor{keyword}{from}\ torch.utils.data\ \textcolor{keyword}{import}\ DataLoader}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00006}00006\ \textcolor{keyword}{from}\ torchvision\ \textcolor{keyword}{import}\ transforms}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00007}00007\ \textcolor{keyword}{import}\ json}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00008}00008\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00009}00009\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00010}00010\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00011}00011\ \textcolor{keyword}{from}\ helper\_load\_data\ \textcolor{keyword}{import}\ custom\_datasets}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00012}00012\ \textcolor{keyword}{from}\ helper\_load\_data\ \textcolor{keyword}{import}\ custom\_transform}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00013}00013\ \textcolor{comment}{\#\ from\ helper\_display\ import\ imshow\_compare}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00014}00014\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00015}00015\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00016}00016\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00017}00017\ \textcolor{comment}{\#\ Load\ configuration\ file}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00018}00018\ \textcolor{keyword}{with}\ open(\textcolor{stringliteral}{'./config\_cluster.json'})\ \textcolor{keyword}{as}\ f:}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00019}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_aba16aff84cfca32b04e2443c87155ed3}{00019}}\ \ \ \ \ config\ =\ json.load(f)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00020}00020\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00021}00021\ \textcolor{comment}{\#\ Extract\ configuration\ parameters}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00022}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a354a48431537b39e317e8ae0ae9b9e73}{00022}}\ batch\_size\ =\ config[\textcolor{stringliteral}{'model\_params'}][\textcolor{stringliteral}{'batch\_size'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00023}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a58ef59bc7f4c6d91a9883da6146558a2}{00023}}\ latent\_dim\ =\ config[\textcolor{stringliteral}{'model\_params'}][\textcolor{stringliteral}{'latent\_dim'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00024}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a90a8e4fd61c3ac76cdd9a9a00094738b}{00024}}\ beta\ =\ config[\textcolor{stringliteral}{'model\_params'}][\textcolor{stringliteral}{'beta'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00025}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_adf037c433a0bdd63e906f31482610827}{00025}}\ learning\_rate\ =\ config[\textcolor{stringliteral}{'train\_params'}][\textcolor{stringliteral}{'learning\_rate'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00026}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_ad9001d96d5c173b3e50c53dd26a6e170}{00026}}\ epochs\ =\ config[\textcolor{stringliteral}{'train\_params'}][\textcolor{stringliteral}{'epochs'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00027}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a0947c8e7dd9b58d90cd5434c0ab41fc4}{00027}}\ manual\_seed\ =\ config[\textcolor{stringliteral}{'random\_seed'}][\textcolor{stringliteral}{'manual\_seed'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00028}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a02dbb1d94b9e271dc8c11c4ca33cc452}{00028}}\ cuda\_manual\_seed\ =\ config[\textcolor{stringliteral}{'random\_seed'}][\textcolor{stringliteral}{'cuda\_manual\_seed'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00029}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a99db3d47f55f93d53c78cce02cced8db}{00029}}\ loading\_checkpoint\ =\ config[\textcolor{stringliteral}{'train\_params'}][\textcolor{stringliteral}{'loading\_checkpoint'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00030}00030\ \textcolor{comment}{\#\ Paths\ from\ configuration}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00031}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_acfdb95196876491013760ee5f8905616}{00031}}\ data\_path\_train\ =\ config[\textcolor{stringliteral}{'Path'}][\textcolor{stringliteral}{'train\_data\_path'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00032}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a63cbb72dca11997081742ea48ff05f57}{00032}}\ data\_path\_test\ =\ config[\textcolor{stringliteral}{'Path'}][\textcolor{stringliteral}{'test\_data\_path'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00033}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_af4db04655a48ca25c5e7b68e9d6bc99c}{00033}}\ save\_path\ =\ config[\textcolor{stringliteral}{'Path'}][\textcolor{stringliteral}{'save\_path'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00034}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a1e885ea79a915616f17a3833be2d77a9}{00034}}\ checkpoint\_path\ =\ config[\textcolor{stringliteral}{'Path'}][\textcolor{stringliteral}{'log\_path'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00035}00035\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00036}00036\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00037}00037\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00038}00038\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00039}00039\ \textcolor{comment}{\#\ Set\ random\ seeds\ for\ reproducibility}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00040}00040\ torch.manual\_seed(manual\_seed)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00041}00041\ torch.cuda.manual\_seed(cuda\_manual\_seed)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00042}00042\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00043}00043\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00044}00044\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00045}00045\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00046}00046\ \textcolor{comment}{\#\ DataLoader\ parameters}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00047}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a32df70f877600b1c903126819ac6f99b}{00047}}\ kwargs\ =\ \{\textcolor{stringliteral}{'num\_workers'}:\ 0,\ \textcolor{stringliteral}{'pin\_memory'}:\ \textcolor{keyword}{True}\}\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00048}00048\ \textcolor{comment}{\#\ Initialize\ DataLoaders\ for\ training\ and\ testing}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00049}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_af57fa6c78c132dc5f22676e1d71fc7cd}{00049}}\ train\_loader\ =\ \mbox{\hyperlink{classsrc_1_1helper__load__data_1_1custom__datasets}{custom\_datasets}}(data\_path\_train,transform=custom\_transform,flatten=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00050}00050\ train\_loader\ =\ DataLoader(train\_loader,\ batch\_size=batch\_size,\ shuffle=\textcolor{keyword}{True},\ **kwargs)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00051}00051\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00052}00052\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00053}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a0a62f41c07de4ca6a2cc2b6a5ebbb0f4}{00053}}\ test\_loader\ =\ \mbox{\hyperlink{classsrc_1_1helper__load__data_1_1custom__datasets}{custom\_datasets}}(data\_path\_test,transform=custom\_transform,flatten=\textcolor{keyword}{False})}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00054}00054\ test\_loader\ =\ DataLoader(test\_loader,\ batch\_size=batch\_size,\ shuffle=\textcolor{keyword}{True},\ **kwargs)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00055}00055\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00056}00056\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00057}00057\ \textcolor{comment}{\#\ Initialize\ the\ model\ and\ optimizer}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00058}00058\ \textcolor{keyword}{from}\ helper\_VAEstruc\ \textcolor{keyword}{import}\ VAE,CNN\_VAE}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00059}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a1d5af19b8854d5f804dbf5cd9da9bd28}{00059}}\ model\ =\ \mbox{\hyperlink{classsrc_1_1helper___v_a_estruc_1_1_c_n_n___v_a_e}{CNN\_VAE}}(channel\_in=2,latent\_dim=latent\_dim)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00060}00060\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00061}00061\ \textcolor{comment}{\#\ Setup\ device\ (GPU/CPU)}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00062}00062\ \textcolor{keywordflow}{if}\ torch.cuda.is\_available():\ \textcolor{comment}{\#\ GPU\ is\ available}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00063}00063\ \ \ \ \ \textcolor{keywordflow}{if}\ torch.cuda.device\_count()\ >\ 1:}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00064}00064\ \ \ \ \ \ \ \ \ model\ =\ nn.DataParallel(model)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00065}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a1b78ff87e851a661f38724b9e8b6e5bb}{00065}}\ \ \ \ \ device\ =\ torch.device(\textcolor{stringliteral}{"{}cuda:0"{}})}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00066}00066\ \ \ \ \ model.to(device)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00067}00067\ \textcolor{keywordflow}{else}:\ \ \textcolor{comment}{\#\ only\ cpu\ is\ available}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00068}00068\ \ \ \ \ device\ =\ torch.device(\textcolor{stringliteral}{"{}cpu"{}})}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00069}00069\ \ \ \ \ model.to(device)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00070}00070\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00071}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_acdc89d955ccb8dd61204435f0ac81a0b}{00071}}\ optimizer\ =\ torch.optim.Adam(}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00072}00072\ \ \ \ \ model.parameters(),}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00073}00073\ \ \ \ \ lr=learning\_rate,}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00074}00074\ )}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00075}00075\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00076}00076\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00077}00077\ \textcolor{comment}{\#\ Load\ checkpoint\ if\ specified}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00078}00078\ \textcolor{keywordflow}{if}\ loading\_checkpoint:}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00079}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_ae995ac47ee3df9c868ede605be82317d}{00079}}\ \ \ \ \ checkpoint\ =\ torch.load(checkpoint\_path+\textcolor{stringliteral}{'checkpoint.tar'})}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00080}00080\ \ \ \ \ model.load\_state\_dict(checkpoint[\textcolor{stringliteral}{'model\_state\_dict'}])}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00081}00081\ \ \ \ \ optimizer.load\_state\_dict(checkpoint[\textcolor{stringliteral}{'optimizer\_state\_dict'}])}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00082}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a166236e8c4d091ef711a76983488a06c}{00082}}\ \ \ \ \ current\_epoch\ =\ checkpoint[\textcolor{stringliteral}{'epoch'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00083}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_aa060ca842aa4cce5dfdac29f062ce84f}{00083}}\ \ \ \ \ loss\ =\ checkpoint[\textcolor{stringliteral}{'loss'}]}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00084}00084\ \textcolor{keywordflow}{else}:\ \textcolor{comment}{\#\ use\ the\ initial\ model\ and\ optimiser}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00085}00085\ \ \ \ \ current\_epoch\ =\ 0}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00086}00086\ \ \ \ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00087}00087\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00088}00088\ \ \ \ \ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00089}00089\ \textcolor{comment}{\#\ Define\ the\ loss\ function}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00090}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a91ab1eb6cb06aa284d77270a186ca4be}{00090}}\ \textcolor{keyword}{def\ }\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a91ab1eb6cb06aa284d77270a186ca4be}{lossfunc}}(x,x\_hat,mu,logvar,beta):}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00091}00091\ \ \ \ \ \textcolor{stringliteral}{"{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00092}00092\ \textcolor{stringliteral}{\ \ \ \ Computes\ the\ Variational\ Autoencoder\ (VAE)\ loss\ function,\ combining\ reconstruction\ loss\ and\ KL\ divergence.}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00093}00093\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00094}00094\ \textcolor{stringliteral}{\ \ \ \ Args:}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00095}00095\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ x\ (torch.Tensor):\ Original\ input\ images.}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00096}00096\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ x\_hat\ (torch.Tensor):\ Reconstructed\ images.}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00097}00097\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ mu\ (torch.Tensor):\ Mean\ of\ the\ latent\ variables.}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00098}00098\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ logvar\ (torch.Tensor):\ Log\ variance\ of\ the\ latent\ variables.}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00099}00099\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ beta\ (float):\ Weight\ for\ the\ KL\ divergence\ part\ of\ the\ loss.}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00100}00100\ \textcolor{stringliteral}{}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00101}00101\ \textcolor{stringliteral}{\ \ \ \ Returns:}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00102}00102\ \textcolor{stringliteral}{\ \ \ \ \ \ \ \ torch.Tensor:\ The\ computed\ loss\ value.}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00103}00103\ \textcolor{stringliteral}{\ \ \ \ "{}"{}"{}}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00104}00104\ \ \ \ \ recons\_loss\ =\ nn.functional.binary\_cross\_entropy(x\_hat,\ x,\ reduction=\textcolor{stringliteral}{'sum'})}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00105}00105\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00106}00106\ \ \ \ \ kl\_loss\ =\ -\/0.5\ *\ torch.sum(1\ +\ logvar\ -\/\ mu.pow(2)\ -\/\ logvar.exp())}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00107}00107\ \ \ \ \ \textcolor{comment}{\#\ kl\_loss\ =\ torch.mean(-\/0.5\ *\ torch.sum(1\ +\ logvar\ -\/\ mu.pow(2)\ -\/\ logvar.exp(),\ dim\ =\ 1),\ dim\ =\ 0)}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00108}00108\ \ \ \ \ \textcolor{keywordflow}{return}\ recons\_loss\ +\ beta*\ kl\_loss}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00109}00109\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00110}00110\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00111}00111\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00112}00112\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00113}00113\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00114}00114\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00115}00115\ \textcolor{comment}{\#\ Training\ loop}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00116}00116\ \textcolor{keywordflow}{for}\ epoch\ \textcolor{keywordflow}{in}\ range(current\_epoch,\ epochs+1):}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00117}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a51771d101f4d176d7a348033bbd54e29}{00117}}\ \ \ \ \ mu\_list\ =\ list()}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00118}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a9ac14124457a7092b35991d2355a1a1c}{00118}}\ \ \ \ \ x\_test\_list\ =\ list()}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00119}00119\ \ \ \ \ model.train()}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00120}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a734d59ec4e1e51e131a14169b2e41e33}{00120}}\ \ \ \ \ train\_loss\ =\ 0}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00121}00121\ \ \ \ \ \textcolor{keywordflow}{for}\ x,y\ \textcolor{keywordflow}{in}\ train\_loader:}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00122}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a9014cac11e46bc9db6620bf052c6ebde}{00122}}\ \ \ \ \ \ \ \ \ x\ =\ x.to(device)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00123}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_aabc2f3334e2ef5fe3aa9e648913f28b1}{00123}}\ \ \ \ \ \ \ \ \ x\_hat,mu,logvar\ =\ \mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a1d5af19b8854d5f804dbf5cd9da9bd28}{model}}(x)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00124}00124\ \ \ \ \ \ \ \ \ mu\_list.append(mu.detach())}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00125}00125\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#====\ forwad\ pass}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00126}00126\ \ \ \ \ \ \ \ \ loss\ =\ \mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a91ab1eb6cb06aa284d77270a186ca4be}{lossfunc}}(x,x\_hat,mu,logvar,beta=beta)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00127}00127\ \ \ \ \ \ \ \ \ train\_loss\ +=\ loss.item()}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00128}00128\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#====\ backward\ pass}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00129}00129\ \ \ \ \ \ \ \ \ optimizer.zero\_grad()}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00130}00130\ \ \ \ \ \ \ \ \ loss.backward()}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00131}00131\ \ \ \ \ \ \ \ \ optimizer.step()}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00132}00132\ \ \ \ \ \textcolor{keywordflow}{if}\ epoch\ \%\ 40\ ==\ 0:\ \textcolor{comment}{\#\ save\ model\ every\ 40\ steps}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00133}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a136b311aa27dbb3897334aa94e7f6000}{00133}}\ \ \ \ \ \ \ \ \ save\_model\ =\ \textcolor{stringliteral}{'VAEmodel\_'}+str(epoch)\ +\ \textcolor{stringliteral}{'.pt'}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00134}00134\ \ \ \ \ \ \ \ \ torch.save(model.module.state\_dict(),\ save\_path+save\_model)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00135}00135\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ imshow\_compare(x,x\_hat,n=4,epoch=epoch)}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00136}00136\ \ \ \ \ \ \ \ \ mu\_list\ =\ torch.cat(mu\_list,dim=0)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00137}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a1f1cb770b150f194e6148ca5ddb4adbf}{00137}}\ \ \ \ \ \ \ \ \ save\_mu\ =\ \textcolor{stringliteral}{'mu\_list\_'}+str(epoch)\ +\ \textcolor{stringliteral}{'.pt'}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00138}00138\ \ \ \ \ \ \ \ \ torch.save(mu\_list,\ save\_path+save\_mu)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00139}00139\ \ \ \ \ \ \ \ \ \textcolor{keyword}{with}\ torch.no\_grad():}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00140}00140\ \ \ \ \ \ \ \ \ \ \ \ \ model.eval()}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00141}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_af7a8baae05b09ec2e4a330bd2b7fab29}{00141}}\ \ \ \ \ \ \ \ \ \ \ \ \ mu\_list\_test\ =\ list()}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00142}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a35f74c3d308453a5c76c0f81b241113a}{00142}}\ \ \ \ \ \ \ \ \ \ \ \ \ test\_loss\ =\ 0}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00143}00143\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{keywordflow}{for}\ x,y\ \textcolor{keywordflow}{in}\ test\_loader:}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00144}00144\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ x\ =\ x.to(device)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00145}00145\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ x\_hat,mu,logvar\ =\ \mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a1d5af19b8854d5f804dbf5cd9da9bd28}{model}}(x)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00146}00146\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ loss\ =\ \mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a91ab1eb6cb06aa284d77270a186ca4be}{lossfunc}}(x,x\_hat,mu,logvar,beta=beta)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00147}00147\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ test\_loss\ +=\ loss.item()}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00148}00148\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ mu\_list\_test.append(mu.detach())}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00149}00149\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ x\_test\_list.append(x.detach())}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00150}00150\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00151}00151\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ Save\ the\ 'mu'\ the\ latent\ space}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00152}00152\ \ \ \ \ \ \ \ \ \ \ \ \ mu\_list\_test\ =\ torch.cat(mu\_list\_test,dim=0)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00153}00153\ \ \ \ \ \ \ \ \ \ \ \ \ save\_mu\ =\ \textcolor{stringliteral}{'mu\_list\_test\_'}+str(epoch)\ +\ \textcolor{stringliteral}{'.pt'}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00154}00154\ \ \ \ \ \ \ \ \ \ \ \ \ torch.save(mu\_list\_test,\ save\_path+save\_mu)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00155}00155\ \ \ \ \ \ \ \ \ \ \ \ \ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00156}00156\ \ \ \ \ \ \ \ \ \ \ \ \ x\_test\_list\ =\ torch.cat(x\_test\_list,dim=0)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00157}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a5e2a63451da5891b53d28aac05793822}{00157}}\ \ \ \ \ \ \ \ \ \ \ \ \ save\_x\_test\ =\ \textcolor{stringliteral}{'x\_test\_'}+str(epoch)\ +\ \textcolor{stringliteral}{'.pt'}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00158}00158\ \ \ \ \ \ \ \ \ \ \ \ \ torch.save(x\_test\_list,\ save\_path+save\_x\_test)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00159}00159\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00160}00160\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00161}00161\ \ \ \ \ \ \ \ \ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00162}00162\ \ \ \ \ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00163}00163\ \ \ \ \ print(f\textcolor{stringliteral}{'====>\ Epoch:\ \{epoch\}\ Average\ loss:\{train\_loss/len(train\_loader.dataset):.4f\}'})}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00164}00164\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00165}00165\ \ \ \ \ \textcolor{comment}{\#\ torch.save(model.state\_dict(),\ save\_path+save\_model)\ \ }}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00166}00166\ \textcolor{comment}{\#\ only\ save\ last\ on\ }}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00167}00167\ \textcolor{comment}{\#\ }}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00168}00168\ save\_model\ =\ \textcolor{stringliteral}{'VAEmodel\_'}+\textcolor{stringliteral}{'last'}+\ \textcolor{stringliteral}{'.pt'}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00169}00169\ save\_mu\ =\ \textcolor{stringliteral}{'mu\_list\_'}+\textcolor{stringliteral}{'last'}+\ \textcolor{stringliteral}{'.pt'}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00170}\mbox{\hyperlink{namespacesrc_1_1main__train__on___g_p_u_a02c120827aafc0c35cccc79e69d49ef0}{00170}}\ save\_mu\_test\ =\ \textcolor{stringliteral}{'mu\_list\_test\_'}+\textcolor{stringliteral}{'last'}+\ \textcolor{stringliteral}{'.pt'}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00171}00171\ save\_x\_test\ =\ \textcolor{stringliteral}{'x\_test\_'}+\textcolor{stringliteral}{'last'}+\ \textcolor{stringliteral}{'.pt'}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00172}00172\ \textcolor{comment}{\#\ torch.save(model.state\_dict(),\ save\_path+save\_model)\ \ }}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00173}00173\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00174}00174\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00175}00175\ \textcolor{comment}{\#\ Saving\ torch.nn.DataParallel\ Model\ for\ multi-\/GPU\ training}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00176}00176\ torch.save(model.module.state\_dict(),\ save\_path+save\_model)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00177}00177\ torch.save(mu\_list,\ save\_path+save\_mu)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00178}00178\ torch.save(mu\_list\_test,\ save\_path+save\_mu\_test)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00179}00179\ torch.save(x\_test\_list,\ save\_path+save\_x\_test)}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00180}00180\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00181}00181\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00182}00182\ \textcolor{comment}{\#\ Save\ the\ final\ model\ and\ other\ states}}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00183}00183\ torch.save(\{}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00184}00184\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{'epoch'}:\ epoch,}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00185}00185\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{'model\_state\_dict'}:\ model.module.state\_dict(),}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00186}00186\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{'optimizer\_state\_dict'}:\ optimizer.state\_dict(),}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00187}00187\ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{stringliteral}{'loss'}:\ loss,}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00188}00188\ \ \ \ \ \ \ \ \ \ \ \ \ \},\ checkpoint\_path+\textcolor{stringliteral}{'checkpoint.tar'})}
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00189}00189\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00190}00190\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00191}00191\ }
\DoxyCodeLine{\Hypertarget{main__train__on___g_p_u_8py_source_l00192}00192\ }

\end{DoxyCode}
